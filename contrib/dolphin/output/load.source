drop database if exists load;
NOTICE:  database "load" does not exist, skipping
create database load dbcompatibility 'B';
\c load
create table t_load_data_0037(c_id int,c_name varchar(50),c_age int,c_gender varchar(11));
load data infile '@abs_builddir@/data/load-double_terminated.txt'
into table t_load_data_0037 character set 'sql_ascii'
fields terminated by '!' enclosed by '*'
lines starting by '[' terminated by ')]';
select * from t_load_data_0037;
 c_id | c_name | c_age | c_gender 
------+--------+-------+----------
    1 | amy1   |    18 | 男
    2 | amy2   |    17 | 女
    3 | 小明   |    16 | 
(3 rows)

-- test tail space
create table t_load_tailspace(c_01 int primary key,c_02 int,c_03 text);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "t_load_tailspace_pkey" for table "t_load_tailspace"
load data infile '@abs_builddir@/data/load-tailspace.txt'
    into table t_load_tailspace
    fields terminated by ',' enclosed by ''''
    lines starting by '*' terminated by ';';
select * from t_load_tailspace;
 c_01 |  c_02  |  c_03   
------+--------+---------
 1001 | 123456 | fsdsgf
 1002 | 456789 | 出发点
 1003 | 174852 | fdas153
(3 rows)

-- test float point to int
create table t_load_float(c_01 int primary key,c_02 int,c_03 text);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "t_load_float_pkey" for table "t_load_float"
load data infile '@abs_builddir@/data/load-float.txt'
    into table t_load_float
    fields terminated by ','
    enclosed by ''''
    lines starting by '*'
    terminated by ';';
select * from t_load_float;
 c_01 |  c_02  |  c_03  
------+--------+--------
 1001 |    123 | fsdsgf
 1002 | 456789 | 出发点
(2 rows)

-- test basic insert
create table t_space_float(n int, c1 int, c2 bigint, c3 uint4, c4 uint8);
insert into t_space_float values(1, ' 1  ', '  2  ', ' 3  ', ' 4   ');
insert into t_space_float values(2, ' 1.  ', '  2.  ', ' 3.  ', ' 4.   ');
insert into t_space_float values(3, ' 1.12  ', '  2.17  ', ' 3.19  ', ' 4.12   ');
insert into t_space_float values(4, ' -1.12  ', '  -2.12  ', ' 3.12  ', ' 4.12   ');
insert into t_space_float values(5, ' 1.5  ', '  2.6  ', ' 3.9  ', ' 4.9   '); -- should carry
insert into t_space_float values(5, ' 1.5. ', '  2.6  ', ' 3.9  ', ' 4.9   '); -- should error
ERROR:  invalid input syntax for integer: " 1.5. "
LINE 1: insert into t_space_float values(5, ' 1.5. ', '  2.6  ', ' 3...
                                            ^
CONTEXT:  referenced column: c1
select * from t_space_float order by n;
 n | c1 | c2 | c3 | c4 
---+----+----+----+----
 1 |  1 |  2 | 3  | 4
 2 |  1 |  2 | 3  | 4
 3 |  1 |  2 | 3  | 4
 4 | -1 | -2 | 3  | 4
 5 |  2 |  3 | 4  | 5
(5 rows)

-- test ignore
create  table t_load_ignore(c_01 int primary key,c_02 int default 18,c_03 char(5) default '女',c_04 varchar(15));
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "t_load_ignore_pkey" for table "t_load_ignore"
load data infile '@abs_builddir@/data/load-ignore.txt' ignore
    into table t_load_ignore character set 'utf8'
    fields terminated by ',' enclosed by '"'
    lines starting by '(' terminated by ')';
select * from t_load_ignore order by c_01;
 c_01 | c_02 | c_03  |  c_04  
------+------+-------+--------
   11 |    0 | '男'  | 'test'
   12 |    0 |       | 'test'
   13 |    0 |       | 'test'
   14 |   12 | 'man' | 'test'
   15 |   12 |       | 'test'
   16 |      |       | 'test'
(6 rows)

create table t1(a int, b int);
load data infile '@abs_builddir@/data/load1.csv' into table t1;
select * from t1;
 a | b 
---+---
 1 | 3
 4 | 5
 1 | 5
 3 | 4
(4 rows)

delete t1;
--prefix
load data infile '@abs_builddir@/data/load2.csv' into table t1 lines starting by 'hello';
select * from t1;
 a | b 
---+---
 1 | 3
 1 | 5
(2 rows)

delete t1;
--fileds terminated
load data infile '@abs_builddir@/data/load3.csv' into table t1 fields terminated by 'delimiter' lines starting by 'hello';
select * from t1;
 a | b 
---+---
 1 | 3
 1 | 5
(2 rows)

delete t1;
--lines terminanted
load data infile '@abs_builddir@/data/load4.csv' into table t1 columns terminated by 'delimiter' lines starting by 'hello' terminated by '#';
select * from t1;
 a | b 
---+---
 1 | 3
 1 | 5
(2 rows)

delete t1;
--enclosed by
load data infile '@abs_builddir@/data/load5.csv' into table t1 columns enclosed by '''' terminated by 'delimiter' lines starting by 'hello' terminated by '#';
select * from t1;
 a | b 
---+---
 1 | 3
 1 | 5
(2 rows)

delete t1;
--ecasped by
load data infile '@abs_builddir@/data/load5.csv' into table t1 columns enclosed by '''' terminated by 'delimiter' escaped by E'\\' lines starting by 'hello' terminated by '#';
select * from t1;
 a | b 
---+---
 1 | 3
 1 | 5
(2 rows)

--ignore
create table t2(a int primary key, b char unique);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "t2_pkey" for table "t2"
NOTICE:  CREATE TABLE / UNIQUE will create implicit index "t2_b_key" for table "t2"
insert into t2 values(1, 'a'), (2, 'b');
load data infile '@abs_builddir@/data/load6.csv' ignore into table t2;
select * from t2;
 a | b 
---+---
 1 | a
 2 | b
 3 | c
(3 rows)

--replace
load data infile '@abs_builddir@/data/load6.csv' replace into table t2;
select * from t2;
 a | b 
---+---
 1 | b
 3 | c
(2 rows)

drop table t2;
create table t2(a int primary key, b char unique)with(storage_type = ustore);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "t2_pkey" for table "t2"
NOTICE:  CREATE TABLE / UNIQUE will create implicit index "t2_b_key" for table "t2"
insert into t2 values(1, 'a'), (2, 'b');
load data infile '@abs_builddir@/data/load6.csv' ignore into table t2;
select * from t2;
 a | b 
---+---
 1 | a
 2 | b
 3 | c
(3 rows)

load data infile '@abs_builddir@/data/load6.csv' replace into table t2;
select * from t2;
 a | b 
---+---
 1 | b
 3 | c
(2 rows)

drop table t2;
create table t2(a int primary key, b char unique)with(segment = on);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "t2_pkey" for table "t2"
NOTICE:  CREATE TABLE / UNIQUE will create implicit index "t2_b_key" for table "t2"
insert into t2 values(1, 'a'), (2, 'b');
load data infile '@abs_builddir@/data/load6.csv' ignore into table t2;
select * from t2;
 a | b 
---+---
 1 | a
 2 | b
 3 | c
(3 rows)

load data infile '@abs_builddir@/data/load6.csv' replace into table t2;
select * from t2;
 a | b 
---+---
 1 | b
 3 | c
(2 rows)

--partition
create table t3(a int primary key, b char unique) partition by range(a)
(
    partition p1 values less than (1),
    partition p2 values less than (2),
    partition p3 values less than (10)
);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "t3_pkey" for table "t3"
NOTICE:  CREATE TABLE / UNIQUE will create implicit index "t3_b_tableoid_key" for table "t3"
insert into t3 values(1, 'a'), (2, 'b');
load data infile '@abs_builddir@/data/load6.csv' ignore into table t3;
select * from t3;
 a | b 
---+---
 1 | a
 2 | b
 3 | c
(3 rows)

load data infile '@abs_builddir@/data/load6.csv' replace into table t3;
select * from t3;
 a | b 
---+---
 1 | b
 3 | c
(2 rows)

drop table t3;
create table t3(a int primary key, b char unique) partition by range(a)
(
    partition p1 values less than (1),
    partition p2 values less than (2),
    partition p3 values less than (10)
) with(storage_type = ustore);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "t3_pkey" for table "t3"
NOTICE:  CREATE TABLE / UNIQUE will create implicit index "t3_b_tableoid_key" for table "t3"
insert into t3 values(1, 'a'), (2, 'b');
load data infile '@abs_builddir@/data/load6.csv' ignore into table t3;
select * from t3;
 a | b 
---+---
 1 | a
 2 | b
 3 | c
(3 rows)

load data infile '@abs_builddir@/data/load6.csv' replace into table t3;
select * from t3;
 a | b 
---+---
 1 | b
 3 | c
(2 rows)

--subpartition
create table t4(a int primary key, b char unique) partition by range(a) subpartition by list(b)
(
    partition p1 values less than (1)
    (
        subpartition p11 values('a'),
        subpartition p12 values('b'),
        subpartition p13 values('c')
    ),
    partition p2 values less than (2)
    (
        subpartition p21 values('a'),
        subpartition p22 values('b'),
        subpartition p23 values('c')
    ),
    partition p3 values less than (10)
    (
        subpartition p31 values('a'),
        subpartition p32 values('b'),
        subpartition p33 values('c')
    )
);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "t4_pkey" for table "t4"
NOTICE:  CREATE TABLE / UNIQUE will create implicit index "t4_b_tableoid_key" for table "t4"
insert into t4 values(1, 'a'), (2, 'b');
load data infile '@abs_builddir@/data/load6.csv' ignore into table t4;
select * from t4 order by a;
 a | b 
---+---
 1 | a
 2 | b
 3 | c
(3 rows)

load data infile '@abs_builddir@/data/load6.csv' replace into table t4;
select * from t4 order by a;
 a | b 
---+---
 1 | b
 3 | c
(2 rows)

drop table t4;
create table t4(a int primary key, b char unique) partition by range(a) subpartition by list(b)
(
    partition p1 values less than (1)
    (
        subpartition p11 values('a'),
        subpartition p12 values('b'),
        subpartition p13 values('c')
    ),
    partition p2 values less than (2)
    (
        subpartition p21 values('a'),
        subpartition p22 values('b'),
        subpartition p23 values('c')
    ),
    partition p3 values less than (10)
    (
        subpartition p31 values('a'),
        subpartition p32 values('b'),
        subpartition p33 values('c')
    )
) with(segment = on);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "t4_pkey" for table "t4"
NOTICE:  CREATE TABLE / UNIQUE will create implicit index "t4_b_tableoid_key" for table "t4"
insert into t4 values(1, 'a'), (2, 'b');
load data infile '@abs_builddir@/data/load6.csv' ignore into table t4;
select * from t4 order by a;
 a | b 
---+---
 1 | a
 2 | b
 3 | c
(3 rows)

load data infile '@abs_builddir@/data/load6.csv' replace into table t4;
select * from t4 order by a;
 a | b 
---+---
 1 | b
 3 | c
(2 rows)

--trigger
create table t5(a int primary key, b char unique);
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "t5_pkey" for table "t5"
NOTICE:  CREATE TABLE / UNIQUE will create implicit index "t5_b_key" for table "t5"
create table t6(a varchar(30));
insert into t5 values(1, 'a'), (2, 'b');
create trigger tri1 before insert on t5 for each statement begin insert into t6 values('before_insert_statement'); end;
/
create trigger tri2 before insert on t5 for each row begin insert into t6 values('before_insert_row'); end;
/
create trigger tri3 after insert on t5 for each statement begin insert into t6 values('after_insert_statement'); end;
/
create trigger tri4 after insert on t5 for each row begin insert into t6 values('after_insert_row'); end;
/
create trigger tri5 before delete on t5 for each statement begin insert into t6 values('before_delete_statement'); end;
/
create trigger tri6 before delete on t5 for each row begin insert into t6 values('before_delete_row'); end;
/
create trigger tri7 after delete on t5 for each statement begin insert into t6 values('after_delete_statement'); end;
/
create trigger tri8 after delete on t5 for each row begin insert into t6 values('after_delete_row'); end;
/
load data infile '@abs_builddir@/data/load6.csv' ignore into table t5;
select * from t6;
            a            
-------------------------
 before_insert_statement
 before_insert_row
 before_insert_row
 after_insert_row
 after_insert_statement
(5 rows)

delete t6;
load data infile '@abs_builddir@/data/load6.csv' replace into table t5;
select * from t6;
            a            
-------------------------
 before_insert_statement
 before_insert_row
 before_delete_statement
 before_delete_row
 after_delete_row
 before_delete_row
 after_delete_row
 after_insert_row
 before_insert_row
 before_delete_row
 after_delete_row
 after_insert_row
 after_insert_statement
 after_delete_statement
(14 rows)

--extra data
delete t1;
load data infile '@abs_builddir@/data/load7.csv' into table t1;
ERROR:  extra data after last expected column
CONTEXT:  COPY t1, line 1: "1	1	1"
set dolphin.sql_mode = '';
load data infile '@abs_builddir@/data/load7.csv' into table t1;
select * from t1;
 a | b 
---+---
 1 | 1
 2 | 2
(2 rows)

--less data
create table t7(a int1, b int2, c int4, d int8);
set dolphin.sql_mode = 'sql_mode_strict,sql_mode_full_group,pipes_as_concat,ansi_quotes';
load data infile '@abs_builddir@/data/load7.csv' into table t7;
ERROR:  missing data for column "d"
CONTEXT:  COPY t7, line 1: "1	1	1"
set dolphin.sql_mode = 'pad_char_to_full_length';
load data infile '@abs_builddir@/data/load7.csv' into table t7;
select * from t7;
 a | b | c | d 
---+---+---+---
 1 | 1 | 1 |  
 2 | 2 | 2 |  
(2 rows)

--/N and empty string
create table t8(id int, a varchar(10), b varchar(10));
load data infile '@abs_builddir@/data/load8.csv' into table t8;
select *, a is null, b is null from t8;
 id | a | b | ?column? | ?column? 
----+---+---+----------+----------
  1 |   |   | t        | f
  2 |   |   | t        | t
(2 rows)

--escape data
create table t9(a int, b varchar(10));
load data infile '@abs_builddir@/data/load9.csv' into table t9 fields terminated by ',';
select * from t9;
 a |    b     
---+----------
 1 |         
 2 |         +
   | 
(2 rows)

--more quote case
create table t10(a char(20), b char(20));
load data infile '@abs_builddir@/data/load_quote.csv' into table t10 fields terminated by ',' enclosed by '"' lines terminated by '#';
select * from t10;
          a           |          b           
----------------------+----------------------
 a,b,c                | 
 a"                   | b                   
 a                    | b,c,d"e#"a,"b"c     
(3 rows)

--same quote and delimiter
delete t10;
load data infile '@abs_builddir@/data/load_quote2.csv' into table t10 fields terminated by ',' enclosed by '"' escaped by '"' lines terminated by '#';
select * from t10;
          a           |          b           
----------------------+----------------------
 a"t"n                | hello"world         
 "tab                 | ""nan"              
(2 rows)

--test copy of colname
drop table if exists memos cascade;
NOTICE:  table "memos" does not exist, skipping
create table memos (Id integer,COnTEXT text,tsColA varchar);
copy memos(CONTEXT,tsColA) from '@abs_builddir@/data/column_copy.csv'DELIMITERS ',';
select * from memos;
 Id | COnTEXT |  tsColA  
----+---------+----------
    | aaa     | col2aaa
    | bbb     | col2BBBA
(2 rows)

copy memos(CONTEXt,tSColA) from '@abs_builddir@/data/column_copy.csv'DELIMITERS ',';
select * from memos;
 Id | COnTEXT |  tsColA  
----+---------+----------
    | aaa     | col2aaa
    | bbb     | col2BBBA
    | aaa     | col2aaa
    | bbb     | col2BBBA
(4 rows)

-- test continuous escapes
create table t_load_continuous_escape(c1 varchar(11),c2 text,c3 text);
truncate table t_load_continuous_escape;
load data infile '@abs_builddir@/data/load-continuous_escape.txt'
    into table t_load_continuous_escape
    fields terminated by '***'
    enclosed by ''''
    escaped by e'\\';
select * from t_load_continuous_escape;
  c1   |   c2   |  c3   
-------+--------+-------
 111   | 极\0简 | 123\n
 222\t | 护法的 | 4\b6
 333   |       +| \z
       |        | 
 111   | 极简   | 123
 2     | aaa    | 12
 222\t | 护法的 | 4\b6
 333   | \n     | \z
 111   | 极简   | 123
(8 rows)

-- test escaped char is the same as enclosed char
create table t_load_same(c1 varchar(11),c2 text);
load data infile '@abs_builddir@/data/load-same_escape_enclosed.txt'
    into table t_load_same character set 'sql_ascii'
    fields terminated by e',' enclosed by '\' escaped by '\'
    lines starting by '测试' terminated by ';';
select * from t_load_same;
  c1  |     c2      
------+-------------
 a\aa | ac*a\c*ac
 b\bb | bc&b\c&bc
 ccc  | c,c,c\c,c,c
 ddd  | dcd\cdc
(4 rows)

-- test enclosed equals escape: multiple enclosed chars, end with field terminator
create table t_load_same_quote_escape(a char(20), b char(20));
load data infile '@abs_builddir@/data/load-same_escape_enclosed2.txt'
    into table t_load_same_quote_escape
    fields terminated by ',' enclosed by '"' escaped by '"'
    lines terminated by '#';
select * from t_load_same_quote_escape;
          a           |          b           
----------------------+----------------------
 a"t"n                | hello"world         
 "nan                 | "nan                
 "nan                 | "nan                
 "nan                 | ""na"t"n\n          
(4 rows)

-- test enclosed equals escape: multiple enclosed chars, hit end of line
truncate t_load_same_quote_escape;
load data infile '@abs_builddir@/data/load-same_escape_enclosed3.txt'
    into table t_load_same_quote_escape
    fields terminated by ',' enclosed by '"' escaped by '"'
    lines terminated by '#';
select * from t_load_same_quote_escape;
          a           |          b           
----------------------+----------------------
 a"t"n                | hello"world         
 "nan                 | "nan                
 ""nan                | "nan                
 """nan","""na"t"     | 
(4 rows)

-- test enclosed equals escape: multiple enclosed chars, end with line terminator but not enclosed correct
truncate t_load_same_quote_escape;
load data infile '@abs_builddir@/data/load-same_escape_enclosed4.txt'
    into table t_load_same_quote_escape
    fields terminated by ',' enclosed by '"' escaped by '"'
    lines terminated by '#';
select * from t_load_same_quote_escape;
          a           |          b           
----------------------+----------------------
 a"t"n                | hello"world         
 "nan                 | "nan                
 "nan                 | "nan                
 "nan                 | """na"t"\n#         
(4 rows)

-- test enclosed equals escape: multiple enclosed chars, end with line terminator and enclosed correct
truncate t_load_same_quote_escape;
load data infile '@abs_builddir@/data/load-same_escape_enclosed5.txt'
    into table t_load_same_quote_escape
    fields terminated by ',' enclosed by '\' escaped by '\'
    lines terminated by '#';
select * from t_load_same_quote_escape;
          a           |          b           
----------------------+----------------------
 a\t\0\b\0\a\r\n\n    | hello\world         
 \nan                 | \nan                
 \nan\                | \nan                
 \nan                 | \\\xn\b\0\a\r\n\t\n 
(4 rows)

-- test enclosed char should escapes itself in quoted fields
create table t_load_escape_itself(c1 varchar(11),c2 text);
load data infile '@abs_builddir@/data/load-escape_itself.txt'
    replace into table t_load_escape_itself
    fields terminated by ',' enclosed by '?'
    escaped by '$'
    lines starting by '测试' terminated by ';';
select * from t_load_escape_itself;
  c1  |         c2          
------+---------------------
 a?aa | ac*a??c*ac;测试b?bb
 ccc  | c,c,c$c,c,c
 ddd  | dcd?cdc
(3 rows)

-- test escape of delimiter
create table t_load_escape_delimiter(c2 text);
load data infile '@abs_builddir@/data/load-escape_delimiter.txt'
    replace into table t_load_escape_delimiter
    fields terminated by ',' enclosed by '?'
    escaped by '@'
    lines terminated by ';';
select * from t_load_escape_delimiter;
              c2              
------------------------------
 hello1 ;hello2;hello3;hello4
(1 row)

-- test export & import on sql_ascii encoding
create database db_ascii dbcompatibility = 'b' encoding 'sql_ascii';
\c db_ascii
set datestyle to 'ISO, YMD';
create  table t_load_export_import(
    col1 money,
    col2 boolean,
    col3 CHAR(4),
    col4 CHARACTER(4),
    col5 NCHAR(4),
    col6 VARCHAR(10),
    col7 CHARACTER VARYING(10),
    col8 VARCHAR2(10),
    col9 NVARCHAR2(10),
    col10 TEXT,
    col11 CLOB,
    col12 BLOB,
    col13 RAW,
    col14 BYTEA,
    col15 DATE,
    col16 TIME,
    col17 time with time zone,
    col18 timestamp,
    col19 timestamp with time zone,
    col20 SMALLDATETIME,
    col21 abstime,
    col22 cidr,
    col23 inet,
    col24 macaddr,
    col25 BIT(3),
    col26 BIT VARYING(5),
    col27 UUID,
    col28 tsvector,
    col29 tsquery,
    col30 json,
    col31 jsonb,
    set hll(14),
    col33 int4range,
    col34 int8range,
    col35 numrange,
    col36 tsrange,
    col37 tstzrange,
    col38 daterange,
    col39 HASH16,
    col40 HASH32
);
insert into t_load_export_import
values ('52093.89'::money, true, 'aa', 'aa', 'aa', 'aa', 'aa', 'aa', 'aa', 'aa', 'aa', empty_blob(), HEXTORAW('DEADBEEF'),
        E'\xDEADBEEF', '1900-01-01 00:00:00', '1900-01-01 00:00:00 pst', '1900-01-01 00:00:00', '1900-01-01 00:00:00 pst',
        '1900-01-01 00:00:00', '1900-01-01 00:00:00', '1910-01-01 00:00:00', '10.10.10.10', '10.10.10.10', '08002b010203',
        B'10'::bit(3), B'00', 'a0eebc999c0b4ef8bb6d6bb9bd380a11', 'test', 'test', '{"aa":1}'::json, '{"bb":2}'::jsonb,
        hll_empty(14,-1), '[1,10]', '[1,10]', '[0.00, 10.00]', '[1900-01-01 00:00:00, 2020-01-01 00:00:00]',
        '[1900-01-01 00:00:00 pst, 2020-01-01 00:00:00 pst]', '(1900-01-01, 2020-01-01)','ffff', 'ffffffffffffffffffffffffffffffff');
insert into t_load_export_import
values ('52093.89'::money, true, 'aa', 'aa', 'aa', 'aa', 'aa', 'aa', 'aa', 'aa', 'aa', empty_blob(), HEXTORAW('DEADBEEF'),
        E'\xDEADBEEF', '1900-01-01 00:00:00', '1900-01-01 00:00:00 pst', '1900-01-01 00:00:00', '1900-01-01 00:00:00 pst',
        '1900-01-01 00:00:00', '1900-01-01 00:00:00', '1910-01-01 00:00:00', '10.10.10.10', '10.10.10.10', '08002b010203',
        B'10'::bit(3), B'00', 'a0eebc999c0b4ef8bb6d6bb9bd380a11', 'test', 'test', '{"aa":1}'::json, '{"bb":2}'::jsonb,
        hll_empty(14,-1), '[1,10]', '[1,10]', '[0.00, 10.00]', '[1900-01-01 00:00:00, 2020-01-01 00:00:00]',
        '[1900-01-01 00:00:00 pst, 2020-01-01 00:00:00 pst]', '(1900-01-01, 2020-01-01)','ffff', 'ffffffffffffffffffffffffffffffff');
insert into t_load_export_import
values ('52093.89'::money, true, 'aa', 'aa', 'aa', 'aa', 'aa', 'aa', 'aa', 'aa', 'aa', empty_blob(), HEXTORAW('DEADBEEF'),
        E'\xDEADBEEF', '1900-01-01 00:00:00', '1900-01-01 00:00:00 pst', '1900-01-01 00:00:00', '1900-01-01 00:00:00 pst',
        '1900-01-01 00:00:00', '1900-01-01 00:00:00', '1910-01-01 00:00:00', '10.10.10.10', '10.10.10.10', '08002b010203',
        B'10'::bit(3), B'00', 'a0eebc999c0b4ef8bb6d6bb9bd380a11', 'test', 'test', '{"aa":1}'::json, '{"bb":2}'::jsonb,
        hll_empty(14,-1), '[1,10]', '[1,10]', '[0.00, 10.00]', '[1900-01-01 00:00:00, 2020-01-01 00:00:00]',
        '[1900-01-01 00:00:00 pst, 2020-01-01 00:00:00 pst]', '(1900-01-01, 2020-01-01)','ffff', 'ffffffffffffffffffffffffffffffff');
copy (select * from t_load_export_import) to '@abs_builddir@/data/load-export_import.txt';
truncate table t_load_export_import;
load data infile '@abs_builddir@/data/load-export_import.txt' into table t_load_export_import;
select * from t_load_export_import;
    col1    | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 |  col13   |      col14       |   col15    |  col16   |    col17    |         col18          |         col19          |        col20        |         col21          |     col22      |    col23    |       col24       | col25 | col26 |                col27                 | col28  | col29  |  col30   |   col31   |                            set                             | col33  | col34  |    col35     |                     col36                     |                        col37                        |          col38          |      col39       |              col40               
------------+------+------+------+------+------+------+------+------+-------+-------+-------+----------+------------------+------------+----------+-------------+------------------------+------------------------+---------------------+------------------------+----------------+-------------+-------------------+-------+-------+--------------------------------------+--------+--------+----------+-----------+------------------------------------------------------------+--------+--------+--------------+-----------------------------------------------+-----------------------------------------------------+-------------------------+------------------+----------------------------------
 $52,093.89 | t    | aa   | aa   | aa   | aa   | aa   | aa   | aa   | aa    | aa    |       | DEADBEEF | \xde414442454546 | 1900-01-01 | 00:00:00 | 00:00:00-08 | 1900-01-01 00:00:00-08 | 1900-01-01 00:00:00-08 | 1900-01-01 00:00:00 | 1910-01-01 00:00:00-08 | 10.10.10.10/32 | 10.10.10.10 | 08:00:2b:01:02:03 | 010   | 00    | a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11 | 'test' | 'test' | {"aa":1} | {"bb": 2} | \x484c4c00000000002b05000000000000000000000000000000000000 | [1,11) | [1,11) | [0.00,10.00] | ["1900-01-01 00:00:00","2020-01-01 00:00:00"] | ["1900-01-01 00:00:00-08","2020-01-01 00:00:00-08"] | [1900-01-02,2020-01-01) | 000000000000ffff | ffffffffffffffffffffffffffffffff
 $52,093.89 | t    | aa   | aa   | aa   | aa   | aa   | aa   | aa   | aa    | aa    |       | DEADBEEF | \xde414442454546 | 1900-01-01 | 00:00:00 | 00:00:00-08 | 1900-01-01 00:00:00-08 | 1900-01-01 00:00:00-08 | 1900-01-01 00:00:00 | 1910-01-01 00:00:00-08 | 10.10.10.10/32 | 10.10.10.10 | 08:00:2b:01:02:03 | 010   | 00    | a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11 | 'test' | 'test' | {"aa":1} | {"bb": 2} | \x484c4c00000000002b05000000000000000000000000000000000000 | [1,11) | [1,11) | [0.00,10.00] | ["1900-01-01 00:00:00","2020-01-01 00:00:00"] | ["1900-01-01 00:00:00-08","2020-01-01 00:00:00-08"] | [1900-01-02,2020-01-01) | 000000000000ffff | ffffffffffffffffffffffffffffffff
 $52,093.89 | t    | aa   | aa   | aa   | aa   | aa   | aa   | aa   | aa    | aa    |       | DEADBEEF | \xde414442454546 | 1900-01-01 | 00:00:00 | 00:00:00-08 | 1900-01-01 00:00:00-08 | 1900-01-01 00:00:00-08 | 1900-01-01 00:00:00 | 1910-01-01 00:00:00-08 | 10.10.10.10/32 | 10.10.10.10 | 08:00:2b:01:02:03 | 010   | 00    | a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11 | 'test' | 'test' | {"aa":1} | {"bb": 2} | \x484c4c00000000002b05000000000000000000000000000000000000 | [1,11) | [1,11) | [0.00,10.00] | ["1900-01-01 00:00:00","2020-01-01 00:00:00"] | ["1900-01-01 00:00:00-08","2020-01-01 00:00:00-08"] | [1900-01-02,2020-01-01) | 000000000000ffff | ffffffffffffffffffffffffffffffff
(3 rows)

\c postgres
drop database if exists load;
drop database if exists db_ascii;
